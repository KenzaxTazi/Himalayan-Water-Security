# Notes for supervision

## 2nd July 2020

### Correpondence

* Sent email to Hamish, still waiting for response

### MRes Report

Written rough drafts of:

* Introduction (Section 1)
* Data (Section 2)
* Soft k means clustering (Section 4.1.1)
* Gaussian Processes (Section 4.2.1)

### Rolling Cross Validation

As we are trying to extrapolate to the future this method is more approriate for cross validation. The corresponding training set consists only of observations that occurred prior to the observation that forms the test set. Thus, no future observations can be used in constructing the forecast. Since it is not possible to obtain a reliable forecast based on a small training set, the earliest observations are not considered as test sets.

![image](https://dl.dropboxusercontent.com/s/jlkm3ejx3v3rexb/fXZ6k.png?dl=0)

I'm using a class derived from Sklearn's `BaseGenerator` object with 5 splits.

|               | 35.5°N, 74.5°E | 34.5°N, 77.75°E | 34.25°N, 80.5°E | 35.5°N, 74.5°E | 35.5°N, 74.5°E |
| ------------- | -------------- | -------------- | -------------- | -------------- | -------------- |
| Fold 1 R2  | -0.005| -0.772| 0.823 | 0.448 | 0.376 |
| Fold 2 R2  | 0.305 | 0.496 | 0.795 | 0.472 | 0.050 |
| Fold 3 R2  | 0.258 | 0.611 | 0.664 | 0.510 | 0.379 |
| Fold 4 R2  | 0.179 | 0.071 | 0.786 | 0.514 | 0.437 |
| Fold 5 R2  | 0.417 | -0.094| 0.848 | 0.652 | 0.483 |
| Mean R2    | 0.231 | 0.062 | 0.783 | 0.519 | 0.345 |

|               | 35.5°N, 74.5°E | 34.5°N, 77.75°E | 34.25°N, 80.5°E | 35.5°N, 76.5°E | 36.25°N, 75.0°E |
| ------------- | -------------- | -------------- | -------------- | -------------- | -------------- |
| Fold 1 MSE | 2.381 | 1.798 | 0.138 | 1.268 | 1.095 |
| Fold 2 MSE | 1.523 | 0.471 | 0.183 | 1.145 | 1.663 |
| Fold 3 MSE | 1.558 | 0.301 | 0.504 | 0.721 | 1.172 |
| Fold 4 MSE | 1.402 | 0.745 | 0.235 | 0.784 | 0.870 |
| Fold 5 MSE | 1.309 | 0.676 | 0.187 | 0.543 | 0.823 |
| Mean MSE   | 1.634 | 0.798 | 0.249 | 0.893 | 1.124 |

### Ensemble

The ensemble was not producing the expected results because it the EDA members are run on a coarser grid (0.5° resolution) than the high resolution ERA5 data on the 0.25° grid (HRES). This explains last weeks poor results. Comparing to the average of the EDA members does not however give the desired result.

The predictive skill of the averaged EDA model is better for both training and validation data.

Below are results for a single location (not cross validated).

|               | Training R2 | Training RMSE | Validation R2 | Validation RMSE | Predicted TP mean | Predicted TP std |
| ------------- | ----------- | ------------- | ------------- | --------------- | ----------------- | ---------------- |
| Run 0 | 0.820 | 0.246 | 0.467 | 0.681 | 2.234 | 0.711 |
| Run 1 | 0.806 | 0.256 | 0.432 | 0.706 | 2.232 | 0.648 |
| Run 2 | 0.813 | 0.250 | 0.473 | 0.655 | 2.245 | 0.711 |
| Run 3 | 0.796 | 0.265 | 0.487 | 0.665 | 2.233 | 0.648 |
| Run 4 | 0.815 | 0.237 | 0.446 | 0.673 | 2.227 | 0.689 |
| Run 5 | 0.799 | 0.267 | 0.434 | 0.717 | 2.234 | 0.658 |
| Run 6 | 0.835 | 0.210 | 0.467 | 0.692 | 2.232 | 0.653 |
| Run 7 | 0.807 | 0.241 | 0.457 | 0.642 | 2.193 | 0.663 |
| Run 8 | 0.803 | 0.265 | 0.217 | 0.994 | 2.139 | 0.984 |
| Run 9 | 0.803 | 0.269 | 0.432 | 0.696 | 2.257 | 0.733 |
| Ensemble | 0.818 | 0.231 | 0.477 | 0.637 | 2.222 | 0.709 |
| Averaged EDA data |  0.864 | 0.173 | 0.491 | 0.622 | 2.280 | 0.691 |
| HRES data | 0.863 | 0.260 | 0.416 | 0.964 | 3.128 | 0.992 |

### Clusters predictions

Training using all the clusters is very computationally expensive, even on JASMIN. Instead, I have opted to randomly sample a subset of locations and times from each cluster using the averaged EDA data (MUCH MUCH MORE scalable). Future sampling can be done more consistently.

|               | Training R2 | Training RMSE | Validation R2 | Validation RMSE | Predicted TP mean | Predicted TP std |
| ------------- | ----------- | ------------- | ------------- | --------------- | ----------------- | ---------------- |
| Averaged EDA data (seed = 42, 1,000pts) | 0.845 | 0.489 | 0.072 | 1.864 | 1.760 | 2.418 |
| Averaged EDA data (seed = 42, 5,000pts) | 0.885 | 0.082 | __0.685__ | 0.239 | 1.424 | 0.255 |

* Do I even want to cross validate at this point?
* Running on JASMIN is not any faster than on my laptop :(

### Cluster as an input

Adding the cluster as a feature doesn't add much.

|               | Training R2 | Training RMSE | Validation R2 | Validation RMSE | Predicted TP mean | Predicted TP std |
| ------------- | ----------- | ------------- | ------------- | --------------- | ----------------- | ---------------- |
| Averaged EDA data (seed = 42, 1,000pts) | 0.845 | 0.698 | 0.053 | 1.379 | 1.755 | 2.425 |
| Averaged EDA data (seed = 42, 5000pts) | 0.842 | 0.640 | 0.428 | 1.309 | 1.775 | 2.392 |

### Possible next steps

* Calculate EOFs of interest and insert as inputs
* Configure GPflow for for GPUs
* Continue writing report
